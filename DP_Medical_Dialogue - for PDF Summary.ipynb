{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michael-David-Lam/Medical-Dialogue-Summary/blob/Bart-base-model/Medical_Dialogue_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjUfY5H9krGy"
      },
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o60gSIhY-qa",
        "outputId": "2c28f95c-f2ab-4dcb-e5ee-d51ae152de00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
            "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.5.2\n",
            "    Uninstalling accelerate-1.5.2:\n",
            "      Successfully uninstalled accelerate-1.5.2\n",
            "Successfully installed accelerate-1.6.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=f3a24eb2deb7893841866b33da91d1b839baa150df74bd0b82ce3b5ad62fb141\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Collecting peft\n",
            "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.6.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2024.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.1.31)\n",
            "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: peft\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "Successfully installed peft-0.15.2\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!pip install -U transformers\n",
        "!pip install -U datasets\n",
        "!pip install -U accelerate\n",
        "!pip install -U evaluate\n",
        "!pip install -U rouge_score\n",
        "!pip install -U peft\n",
        "!pip install sentencepiece\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZjLJfvUkwXe"
      },
      "source": [
        "# Import Dataset GitHub Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1HGBSm5szz2",
        "outputId": "60fac5d5-df97-4406-b3d6-229e780597ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'MTS-Dialog'...\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 98 (delta 18), reused 3 (delta 3), pack-reused 72 (from 1)\u001b[K\n",
            "Receiving objects: 100% (98/98), 1.19 MiB | 3.13 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "!git clone https://github.com/abachaa/MTS-Dialog.git\n",
        "\n",
        "# Load data\n",
        "training_data =pd.read_csv('/content/MTS-Dialog/Main-Dataset/MTS-Dialog-TrainingSet.csv')\n",
        "validation_data = pd.read_csv('/content/MTS-Dialog/Main-Dataset/MTS-Dialog-ValidationSet.csv')\n",
        "test_data = pd.read_csv('/content/MTS-Dialog/Main-Dataset/MTS-Dialog-TestSet-1-MEDIQA-Chat-2023.csv')\n",
        "\n",
        "# Rename columns\n",
        "training_data = training_data.rename(columns={'context': 'input_text', 'target': 'target_text'})\n",
        "\n",
        "from datasets import Dataset\n",
        "train_dataset = Dataset.from_pandas(training_data)\n",
        "val_dataset = Dataset.from_pandas(validation_data)\n",
        "test_dataset = Dataset.from_pandas(test_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOMUe_kZk4Mn"
      },
      "source": [
        "# Define Model and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "0d4257e3cb3549e6aaffe0d805a65cb7",
            "535da7223a8349f79f5b4251095dc6f2",
            "96a5050fac544206866387f5485679b1",
            "fda5ff95555e455faf99add089863ef9",
            "4057bdfdd9f34eccbf47c63618942c81",
            "1e6d56fe5b40408fb62afaacfe28cfc4",
            "0d2d0292feef4eafad5fb0a44d22446c",
            "7d62209128c84af187714e5865cec4b4",
            "c74cfe70d79d4d32944cfe6553f8c69e",
            "4b276cf9ceff41fa9f9c3b4416f41d27",
            "981494c900b044ada7731782416521bf",
            "75c790f143d54c54ada7efb8cdcc1ca5",
            "42c6f6d4766c4d579d8d631d6676a464",
            "e812eae1208b4b709e452cf76f9c775f",
            "91cc733fc0e14a1a952d5dad673af1aa",
            "5217ecaa653647a68659fd986d01051e",
            "4b43416263fe49a8a5c3442cf88a361d",
            "7fa1f0a1618f4b88b650047a93303426",
            "3445c8ee4ac2462293a85012854adb27",
            "12c8ce11427d4fb0beef8883bc3f7a2a",
            "f51dbf6fc0324b5688ca12e522eeea9f",
            "f4b437aff4a2464fb276607bf1852b40",
            "db0c1d4480f245d09338173db035b9ab",
            "5731898279ea4334b7ce5808d315398f",
            "267d423015c44edd96c87ca885a8716a",
            "8c515cb6ceb34266acb186f90d70a069",
            "dfe88ed6fd9142e993bd6dcdc740a3d8",
            "223fcf240b06456dada4d28557e59e93",
            "34e952e84c93411992b6a377a1e56da5",
            "aeb377e1762d47099c8385e17ee1df17",
            "0be5616526254073be89c9daa883709f",
            "84da64751bd741c48b36f941f30c8424",
            "bfb54d99f29b4dea94914bbb5acd060d",
            "ff9ca662cb37480eba5013f189022130",
            "d96af0d326444c22a48ed534a7a510c7",
            "e5aa2e52fe4845a9b9b6a37262050b72",
            "577f0d40cab84fb6a0105b3e55569032",
            "5e43d73217494233bee0a0b5237dff62",
            "75136276a6bb47a494a35e7153b176ce",
            "5780094675234af2aa3840ce9daf4bd9",
            "cd1c71bb0ac046df8581e169548fa17d",
            "e16462581b12495e9f0f9861c8a8e1c7",
            "19e25217828f498389bf2e9f68b04574",
            "973b065780a64812a8698e911e0bce79"
          ]
        },
        "id": "lY7IUaX_37Tp",
        "outputId": "97855781-2146-41a5-d245-cb9c12b93f2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d4257e3cb3549e6aaffe0d805a65cb7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75c790f143d54c54ada7efb8cdcc1ca5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db0c1d4480f245d09338173db035b9ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff9ca662cb37480eba5013f189022130",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import BartTokenizer, BartModel\n",
        "\n",
        "model_name = \"facebook/bart-base\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Focuse on the five key medical sections for summary:\n",
        "    - Chief complaint (cc)\n",
        "    - History of present illness (genhx)\n",
        "    - Past medical history (pastmedicalhx)\n",
        "    - Diagnosis (diagnosis)\n",
        "    - Treatment plan (plan)\n",
        "    \"\"\"\n",
        "    # Define only the sections we care about\n",
        "    TARGET_SECTIONS = [\n",
        "        ('chief_complaint', 'cc'),\n",
        "        ('history_of_present_illness', 'genhx'),\n",
        "        ('past_medical_history', 'pastmedicalhx'),\n",
        "        ('diagnosis', 'diagnosis'),\n",
        "        ('treatment_plan', 'plan')\n",
        "    ]\n",
        "\n",
        "    df['dialogue_id'] = df['ID'].astype(str)\n",
        "    grouped = df.groupby('dialogue_id')\n",
        "\n",
        "    structured_data = []\n",
        "\n",
        "    for dialogue_id, group in grouped:\n",
        "        # Combine all dialogue turns\n",
        "        full_dialogue = ' '.join(group['dialogue'].tolist())\n",
        "\n",
        "        # Extract all sections\n",
        "        sections = {}\n",
        "        for _, row in group.iterrows():\n",
        "            section_key = row['section_header'].lower().strip()\n",
        "            sections[section_key] = row['section_text'].strip()\n",
        "\n",
        "        # Build target text\n",
        "        target_parts = []\n",
        "        for standard_name, source_name in TARGET_SECTIONS:\n",
        "            if source_name in sections and sections[source_name]:\n",
        "                target_parts.append(f\"<{standard_name}>{sections[source_name]}</{standard_name}>\")\n",
        "\n",
        "        target_text = ' '.join(target_parts)\n",
        "\n",
        "        # Prompt\n",
        "        input_prompt = (\n",
        "            f\"Summarize the following doctor-patient dialogue into a clinical note \"\n",
        "            f\"focusing on chief complaint, history of present illness, past medical history, \"\n",
        "            f\"diagnosis, and treatment plan: {full_dialogue}\"\n",
        "        )\n",
        "\n",
        "        structured_data.append({\n",
        "            'input_text': input_prompt,\n",
        "            'target_text': target_text,\n",
        "            'dialogue_id': dialogue_id\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(structured_data)\n",
        "\n",
        "# Apply preprocessing\n",
        "training_structured = preprocess_data(training_data)\n",
        "validation_structured = preprocess_data(validation_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uFOWEMvMAb9v"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DoctorPatientDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_input_length=512, max_target_length=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_input_length = max_input_length\n",
        "        self.max_target_length = max_target_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Access data using .iloc to ensure integer-based indexing\n",
        "        item = self.data.iloc[idx]  # Use .iloc for integer-based indexing\n",
        "        input_text = item['input_text']\n",
        "        target_text = item['target_text']\n",
        "\n",
        "        # Tokenize inputs\n",
        "        input_encodings = self.tokenizer(\n",
        "            input_text,\n",
        "            max_length=self.max_input_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Tokenize targets\n",
        "        target_encodings = self.tokenizer(\n",
        "            target_text,\n",
        "            max_length=self.max_target_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Replace padding token id with -100 for loss calculation\n",
        "        labels = target_encodings['input_ids']\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_encodings['input_ids'].flatten(),\n",
        "            'attention_mask': input_encodings['attention_mask'].flatten(),\n",
        "            'labels': labels.flatten()\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84Hmz0_nlFhf"
      },
      "source": [
        "## Create Train/Val Tokenized Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "58WsHnfWfWwz"
      },
      "outputs": [],
      "source": [
        "# Create tokenized datasets\n",
        "train_tokenized = DoctorPatientDataset(training_structured, tokenizer)\n",
        "val_tokenized = DoctorPatientDataset(validation_structured, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfWudPwBlMg_"
      },
      "source": [
        "## Init Model and Lora Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b432056f1b0a4b52803f74d65d3bbf9e",
            "cc83094bab0f4638812091b9c71f01fb",
            "cfb6070847484775ac9d2a390b2c6375",
            "e78d74e5531e435b9ae435d06f57ee88",
            "3015634104024df786ec272cd03e56ba",
            "51c55af2db7c4bcbb054b46f22519607",
            "ef2e148564dc419b95252746978bf99c",
            "51f186e2e8c1434eb861d8be77dceb3a",
            "a3e0093d010d42dfa7b59a20b559b4e5",
            "7f23f93af0db420c81f503750f3903ca",
            "5c65fc6dd2734e6c83edbb4bfbaa1a2c"
          ]
        },
        "id": "vdvvXx7w0bZo",
        "outputId": "8907a90a-ef3a-4c74-d3ad-a9b7d12c4a32"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b432056f1b0a4b52803f74d65d3bbf9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import BartForConditionalGeneration\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "# Example data preparation\n",
        "\n",
        "# Initialize model with LoRA\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "lora_config = LoraConfig(\n",
        "    r=4,\n",
        "    lora_alpha=32,\n",
        "    # target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM\n",
        ")\n",
        "# Wrap model with LoRA\n",
        "model = get_peft_model(model, lora_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2Imha-To5f9S"
      },
      "outputs": [],
      "source": [
        "from transformers import GenerationConfig\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    temperature=0.9,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    do_sample=True,\n",
        "    repetition_penalty=2.0,\n",
        "    no_repeat_ngram_size=4,\n",
        "    num_beams=1,\n",
        "    max_length=128\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNKf4yENlSMg"
      },
      "source": [
        "# Define Training Args and Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "9585f62b979240c59837fa9f7c4d7983",
            "a76aee8546484835aa76e560ac527d63",
            "3b6f3d368fde4a77979ec0bfd69cb885",
            "992b93761c314167a4ee697e5703362b",
            "e70dc9db261d4fb3b3b352ed88d6efcd",
            "7a8da94f35fb42208437ee163f11c84a",
            "cf3e8fdc3de74db1b1cb231d510282b6",
            "500a55755b37402e9b894a9df3541609",
            "4e7ecf62a542444dbad0653b8d0f7ccf",
            "a09c92f283454b2983fef91504f8d7c8",
            "adeba752d52a4e0abab5839a23563581"
          ]
        },
        "id": "u4jnRXxk8K8g",
        "outputId": "b92fe304-0d1c-42c6-adea-36349bb7e1be"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9585f62b979240c59837fa9f7c4d7983",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-dc9f55b3af6a>:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import evaluate\n",
        "from transformers import GenerationConfig\n",
        "from transformers.trainer_utils import IntervalStrategy, SaveStrategy\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Replace -100 with the pad token id for decoding labels\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    # Ensure token IDs are within valid range\n",
        "    vocab_size = len(tokenizer)\n",
        "    predictions = np.where(\n",
        "        (predictions >= 0) & (predictions < vocab_size),\n",
        "        predictions,\n",
        "        tokenizer.unk_token_id  # Replace out-of-range IDs with unknown token\n",
        "    )\n",
        "\n",
        "    # Decode predictions and labels\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        use_stemmer=True\n",
        "    )\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    # Replace 'evaluation_strategy' with 'eval_strategy'\n",
        "    eval_strategy=IntervalStrategy.EPOCH,\n",
        "    save_strategy=IntervalStrategy.EPOCH,\n",
        "    learning_rate=3e-4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=20,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    generation_max_length=128,\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,\n",
        "    logging_strategy =\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=val_tokenized,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vhie6DVlW6R"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "f8qMpgzJ58C1",
        "outputId": "b0fc6854-361a-4ea7-eff0-6a11f300d90c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3020' max='3020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3020/3020 23:45, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.867600</td>\n",
              "      <td>1.569056</td>\n",
              "      <td>0.055900</td>\n",
              "      <td>0.022600</td>\n",
              "      <td>0.034600</td>\n",
              "      <td>0.034400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.862000</td>\n",
              "      <td>1.621934</td>\n",
              "      <td>0.085100</td>\n",
              "      <td>0.037700</td>\n",
              "      <td>0.059100</td>\n",
              "      <td>0.059900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.831600</td>\n",
              "      <td>1.557555</td>\n",
              "      <td>0.043700</td>\n",
              "      <td>0.019500</td>\n",
              "      <td>0.027000</td>\n",
              "      <td>0.027900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.838100</td>\n",
              "      <td>1.571300</td>\n",
              "      <td>0.071500</td>\n",
              "      <td>0.030300</td>\n",
              "      <td>0.047800</td>\n",
              "      <td>0.047700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.762400</td>\n",
              "      <td>1.526974</td>\n",
              "      <td>0.047500</td>\n",
              "      <td>0.020900</td>\n",
              "      <td>0.030400</td>\n",
              "      <td>0.031200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.748300</td>\n",
              "      <td>1.552716</td>\n",
              "      <td>0.073400</td>\n",
              "      <td>0.030800</td>\n",
              "      <td>0.049200</td>\n",
              "      <td>0.049700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.743200</td>\n",
              "      <td>1.569546</td>\n",
              "      <td>0.080700</td>\n",
              "      <td>0.034300</td>\n",
              "      <td>0.055100</td>\n",
              "      <td>0.056500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.706300</td>\n",
              "      <td>1.621934</td>\n",
              "      <td>0.116800</td>\n",
              "      <td>0.054800</td>\n",
              "      <td>0.086100</td>\n",
              "      <td>0.086900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.774800</td>\n",
              "      <td>1.592064</td>\n",
              "      <td>0.113800</td>\n",
              "      <td>0.050500</td>\n",
              "      <td>0.083200</td>\n",
              "      <td>0.084900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.714200</td>\n",
              "      <td>1.592773</td>\n",
              "      <td>0.112300</td>\n",
              "      <td>0.050500</td>\n",
              "      <td>0.084600</td>\n",
              "      <td>0.084800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.703000</td>\n",
              "      <td>1.586054</td>\n",
              "      <td>0.111300</td>\n",
              "      <td>0.053500</td>\n",
              "      <td>0.081600</td>\n",
              "      <td>0.081100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.704800</td>\n",
              "      <td>1.601431</td>\n",
              "      <td>0.129200</td>\n",
              "      <td>0.061700</td>\n",
              "      <td>0.096400</td>\n",
              "      <td>0.097400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.696200</td>\n",
              "      <td>1.562041</td>\n",
              "      <td>0.092700</td>\n",
              "      <td>0.043100</td>\n",
              "      <td>0.068400</td>\n",
              "      <td>0.068600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.650600</td>\n",
              "      <td>1.554210</td>\n",
              "      <td>0.092700</td>\n",
              "      <td>0.043700</td>\n",
              "      <td>0.070100</td>\n",
              "      <td>0.070700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.624700</td>\n",
              "      <td>1.552531</td>\n",
              "      <td>0.093100</td>\n",
              "      <td>0.044700</td>\n",
              "      <td>0.069200</td>\n",
              "      <td>0.069200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.650900</td>\n",
              "      <td>1.565517</td>\n",
              "      <td>0.097900</td>\n",
              "      <td>0.045600</td>\n",
              "      <td>0.072200</td>\n",
              "      <td>0.073100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.653900</td>\n",
              "      <td>1.554157</td>\n",
              "      <td>0.090200</td>\n",
              "      <td>0.041500</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.066900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.640800</td>\n",
              "      <td>1.551719</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.040800</td>\n",
              "      <td>0.065600</td>\n",
              "      <td>0.066600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.678300</td>\n",
              "      <td>1.557543</td>\n",
              "      <td>0.107200</td>\n",
              "      <td>0.052700</td>\n",
              "      <td>0.082800</td>\n",
              "      <td>0.084600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.666400</td>\n",
              "      <td>1.559854</td>\n",
              "      <td>0.107400</td>\n",
              "      <td>0.051500</td>\n",
              "      <td>0.080100</td>\n",
              "      <td>0.081100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('./clinical_note_model/tokenizer_config.json',\n",
              " './clinical_note_model/special_tokens_map.json',\n",
              " './clinical_note_model/vocab.json',\n",
              " './clinical_note_model/merges.txt',\n",
              " './clinical_note_model/added_tokens.json')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()\n",
        "model.save_pretrained(\"./clinical_note_model\")\n",
        "tokenizer.save_pretrained(\"./clinical_note_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_pVcbl0lZwq"
      },
      "source": [
        "# Generate Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymTgDfTWu_5S",
        "outputId": "0df59bf8-de44-414e-c1d3-f26af23e3ad1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`generation_config` default values have been modified to match model-specific defaults: {'early_stopping': True, 'num_beams': 4, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2, 'pad_token_id': 1, 'bos_token_id': 0, 'eos_token_id': 2, 'decoder_start_token_id': 2}. If this is not desired, please set these values explicitly.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "CC\n",
            "<history_of_present_illness>The patient is a 43-year-old female who presents with chest pain for the last few nights.  The patient describes it as gnawing sensation that lasts about 10 to 10 seconds, but she has tried taking anything for pain relief and has not been able to get any help.</History_Of_Present_IllNESS>\n",
            "PLAN\n",
            "\n",
            "GENHX\n",
            "\n",
            "CC\n",
            "\n",
            "PASTMEDICALHX\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>The patient is a 58-year-old right leg injury.  The patient states that it was about six months ago that the weakness in the right knee started. She has not really remembered how it happened. He says that he has had this weakness for quite some time now and does not remember what happened to him. This is something that I am very concerned about, but I do remember that she has been having this type of weakness over the last six or seven months.\"  In addition, she describes that her left leg began to have a little bit of pain as well\n",
            "PASTMEDICALHX\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>The patient is a 58-year-old female who presents to my office with her foot twisted.  The patient states that she was in the office on November 20th, 2006 and had some pain immediately after this injury. She has no recollection of what happened but she describes it as very painful.</history__of_____present/present>\n",
            "GENHX\n",
            "<history_of_present_illness>The patient is a 33-year-old white female who presents to me with left knee pain.  She states that she has had some right knee discomfort for the past thirty-six years, but it continues to be very painful and she needs to make sure her chart is correct.</History_Of_Present_Illinity>\n",
            "PASTMEDICALHX\n",
            "\n",
            "CC\n",
            "\n",
            "GENHX\n",
            "\n",
            "PASTMEDICALHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "CC\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>The patient states that he was lifting some things out of the trunk of his car and it started hurting.  The patient says that this is probably the worst pain he has had in his life. He did have a previous history of left wrist pain, but he said that it was before that.\"  He told me that there was a lot of lifting and then it happened to start hurting as well. This is not something that I've ever experienced before. It is just another kind of hand injury. His last one was when he lifted some stuff out from his trunk.</history\n",
            "CC\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>The patient presents to discuss her diet and metabolic syndrome.  The patient states that she has high lipid levels, high blood pressure and a possibility for a metabolic disorder.</History_Of_Present_Guilt>\n",
            "CC\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>The patient is a 50-year-old right-handed female with long standing on and off lower back pain.  The patient states that she was involved in a motor vehicle accident in September of 2005 and started experiencing this abnormal like pain in the lower side of her back, especially on the right side. She also reports that five days later she started having an abnormal type of back ache which she described as \"very abnormal.\"  She said that when she woke up 5 days after the accident, she did not feel anything but she began to have some abnormal kind of pain\n",
            "GENHX\n",
            "<history_of_present_illness>The patient is a 65-year-old female who presents with knee pain for 13 years.  She has had a knee replacement at another facility, and she states that she actually had this in the past when she was treated for her previous knee injury. The patient says that they have also had other knee replacements as well.Â She states however, that there is no current location for this type of procedure. This patient does not have any history of prior knee injuries.</history__of_.present_____\n",
            "GENHX\n",
            "\n",
            "PASTMEDICALHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>The patient is a 85-year-old female who presents with weird muscle pain in her rightbuttocks region.  She states that it radiates from her lower back or spine area and she has difficulty explaining what kind of pain it is. The patient describes it as sharp pain, dullness, but it's very irritating to explain. Her symptoms are difficult to describe because she is not sure about the exact location of the pain. It is also very painful for her due to the fact that she does not have any type of spinal cord injury.\"\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>This is a 2-month-old girl who has had some congestion and coughed more than she ever has before.  She is only two months old and it breaks my heart to see her like this. The breathing has been hard this past week, as well as the irregular breathing where she would breathe very quickly and retract.\"  There have been some irregularions in her breathing but she has not had any irregular airway movements.</history__Of_admption>\n",
            "CC\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>The patient states that she has a fear of pressure in the backside of her head and it comes approximately once a week.  The patient describes that as pins and needles in your head, often it feels like water is running through your face. She denies that this is happening to her but said that sometimes it suppresses some of the pressure.\"  She does not know what else is going on with this because she says that it's just something that happens at least once each week or more every other week.</History_Of_Present_Guilt>\n",
            "GENHX\n",
            "<history_of_present_illness>The patient presents to the office today with a big ol lump in his chest.  The patient states that it has been there for at least a year and it hurts when he feels it, but it is much more tender than it was when she first noticed it. He says that this is causing him pain because of the swelling on the left side. It is very tender and painful when you feel it as well as when they are rubbing it against your chest.\"  At this time, the patient believes that the lump has gotten a lot bigger and stronger over the years.</history\n",
            "GENHX\n",
            "\n",
            "CC\n",
            "<history_of_present_illness>The patient comes in today for a checkup.  The patient states that she thought it would go away on its own, but it has been a couple of weeks now and she thinks it's going to be a little bit too big for her.\"  She has taken Advil for it.</history__of-present_____\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "PASTMEDICALHX\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>The patient is a 34-year-old female who presents to the clinic today for evaluation of her history of epilepsy.  She states that she has had some small seizures in the past, but now she feels strange body aches and feeling confused. In the mornings she wakes up with strange head ache and confusion. This has been occurring before after waking up from sleep.\"  The patient denies any previous epileptic issues.Â Her symptoms are similar to what I have experienced in my past.</history__of_.present_____\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "PASTMEDICALHX\n",
            "\n",
            "DIAGNOSIS\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>The patient is a 20-year-old African American male who was walking off a hilo at work when he felt a pop in his left leg.  The patient states that the pop was in the back of the leg and he has been treated with treatments for this.</history__Of_Present_Guilt>\n",
            "GENHX\n",
            "<history_of_present_illness>This is a 16-year-old male who has been having a lot of problems at school.  According to his reports, he has had an unusual number of questions and interactions with his classmates.</History_Of_Present_Guilt>\n",
            "CC\n",
            "\n",
            "GENHX\n",
            "\n",
            "CC\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>The patient is a 5-year-old male who broke both the bones in his forearm in September of 2007.  He rebroke it about a month ago, and he has been healing very well since that time. The patient states that he did not have any significant bone damage until this time, when he rebrotched the fracture about two months ago. His mother also said that she was surprised to see that his son had broken both his bones so quickly as well. She also told me that her son does not seem to be able to do much more than reb\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "<diagnosis>Flexor carpi radialis, which is a tendon in your forearm that has become inflamed.  The patient was seen by Dr. ABCC and explained to me what is FCTR tendinitis. She did not have her notes with me today because she doesn't have his notes on this.</diagnology>\n",
            "PASTMEDICALHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>The patient is a 50-year-old male with degenerative joint disease of the big toe.  The patient states that he has been complaining of pain in his MPUJ for some time now, which is right where it hurts. He also stated that this pain was getting worse as he was looking at x-ray reports and he had been having more pain over the last few days.\"  His symptoms are consistent with arthritis in the medial pectoral area of his left foot,\"he states.</History_Of_Present_Guilt>\n",
            "PASTMEDICALHX\n",
            "\n",
            "PASTMEDICALHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>This is a 30-year-old female who presents to the office with right hip pain.  She states that she has been dealing with this for about two years now, and her right hurts more than her left. The patient describes it as being approximately 2 years ago on the right. This was presented to us today in the emergency room because of the same problem. Her right hips have been very painful for quite some time. It seems to be consistent with the way she is presenting at the moment.</History_Of_Present_Guilt>\n",
            "GENHX\n",
            "<history_of_present_illness>The patient is a 50-year-old female who presents here with a herniated disc at T8/9.  The patient states that she has taken antiinflammatories, rested, and has not had any surgery. She denies any other complications. All of this is good for the patient's rib pain.\"  There are no problems with her continued progress in managing her rib injury.</history__of_.present_____\n",
            "PASTMEDICALHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>This is a 34-year-old left-handed male who presented to us one month ago for headaches, nausea, and vomiting.  His exams from that time showed no evidence of bowel obstruction and he was released home after his discharge. The patient states that he had similar symptoms on and off after discharge as well as having difficulty concentrating in the last month or so. He has also been experiencing some blurred vision and difficulties concentrating.\"  This is not an indication of any obstructive pulmonary embolism but it is consistent with what he has experienced since discharge.</history__of\n",
            "GENHX\n",
            "\n",
            "PASTMEDICALHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "PASTMEDICALHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "\n",
            "CC\n",
            "\n",
            "GENHX\n",
            "\n",
            "GENHX\n",
            "<history_of_present_illness>The patient is a 71-year-old female who was admitted here in May 2002 with history of hypertension and had bad abdominal pain diarrhea and cramps.  She was diagnosed with chronic obstructive pulmonary disease (C Diff) on 29/03/92, followed by CT imaging of her abdomen and that is when she thought she might have diffuse colitis. The patient states that she has had some type of C Diff as well as an episiotomy for the past several years.Â Her diagnosis was confirmed on 9/02/93.</history__of_____\n",
            "GENHX\n",
            "\n",
            "PASTMEDICALHX\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import GenerationConfig\n",
        "\n",
        "# Define your generation config once\n",
        "generation_config = GenerationConfig(\n",
        "    temperature=0.7,\n",
        "    top_k=60,\n",
        "    top_p=0.95,\n",
        "    do_sample=True,\n",
        "    repetition_penalty=2.4,\n",
        "    no_repeat_ngram_size=2,\n",
        "    num_beams=1,\n",
        "    max_length=128  # You can adjust this\n",
        ")\n",
        "\n",
        "# Function to generate notes from dialogue\n",
        "def generate_note(dialogue):\n",
        "    inputs = tokenizer(\n",
        "        dialogue,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        generation_config=generation_config  # ✅ This is where it goes\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Example usage\n",
        "\n",
        "# List of section headers necessary\n",
        "options = [\"CC\", \"GENHX\", \"PASTMEDICALHX\", \"DIAGNOSIS\", \"PLAN\"]\n",
        "\n",
        "for example in test_dataset:\n",
        "    if example['section_header'] in options:\n",
        "        note = generate_note(example['dialogue'])  # Access the 'dialogue' column\n",
        "        print(example['section_header'])\n",
        "        print(note)  # Or store the note for later use\n",
        "        # print(example['dialogue'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KEQld-v4LKn"
      },
      "source": [
        "## Enchanced Summary Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BUnzz5Ol35iY"
      },
      "outputs": [],
      "source": [
        "# Enhanced generation function that returns structured sections\n",
        "def generate_structured_note(dialogue, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Generates a structured clinical note from dialogue and returns\n",
        "    the extracted sections in a dictionary\n",
        "    \"\"\"\n",
        "    target_sections = [\"chief_complaint\", \"history_of_present_illness\",\n",
        "                      \"past_medical_history\", \"diagnosis\", \"treatment_plan\"]\n",
        "\n",
        "    input_text = f\"Summarize the following doctor-patient dialogue into a clinical note focusing on chief complaint, history of present illness, past medical history, diagnosis, and treatment plan: {dialogue}\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        generation_config=generation_config\n",
        "    )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract the specific sections\n",
        "    sections = extract_sections(generated_text, target_sections)\n",
        "\n",
        "    return sections, generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LBSjnZbby5gF"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "def demo_system(model, tokenizer, test_example):\n",
        "    \"\"\"\n",
        "    Demonstrates the system with a test example\n",
        "    \"\"\"\n",
        "    dialogue = test_example['dialogue']\n",
        "\n",
        "    sections, full_text = generate_structured_note(dialogue, model, tokenizer)\n",
        "\n",
        "    print(\"FULL GENERATED TEXT:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(full_text)\n",
        "    print(\"\\nEXTRACTED SECTIONS:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for section_name, content in sections.items():\n",
        "        print(f\"### {section_name.upper().replace('_', ' ')} ###\")\n",
        "        print(content)\n",
        "        print(\"-\" * 40)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "4lpZ455IPbnw",
        "outputId": "6941c37c-da77-49cf-cecf-6a28c04ca112"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# 1. First, check if your dataset has the right structure:\\nprint(test_dataset.column_names)  # For datasets.Dataset objects\\n# OR\\nprint(test_data.columns)  # For pandas DataFrames\\n\\n# 2. Test with a single example first:\\nif len(test_dataset) > 0:\\n    example = test_dataset[0]\\n    dialogue = example[\\'dialogue\\']  # adjust field name if needed\\n    test_single_example(model, tokenizer, dialogue)\\n\\n# 3. Process a few test examples:\\nresults = process_test_dataset(model, tokenizer, test_dataset, num_examples=3)\\n\\n# 4. Run full evaluation only after verifying the above steps work:\\ntarget_sections = [\"chief_complaint\", \"history_of_present_illness\", \\n                   \"past_medical_history\", \"diagnosis\", \"treatment_plan\"]\\neval_results = evaluate_generated_notes(model, tokenizer, test_dataset, target_sections)\\n'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# First, let's add some debug printing and error handling\n",
        "def evaluate_generated_notes(model, tokenizer, test_dataset, target_sections):\n",
        "    \"\"\"\n",
        "    Evaluates the model on test data and provides section-specific metrics\n",
        "    \"\"\"\n",
        "    results = {section: {\"present\": 0, \"total\": 0} for section in target_sections}\n",
        "    all_generated = []\n",
        "    all_references = []\n",
        "\n",
        "    print(f\"Starting evaluation on {len(test_dataset)} test examples...\")\n",
        "\n",
        "    # Check if test_dataset is a Dataset object or DataFrame\n",
        "    if hasattr(test_dataset, 'to_pandas'):\n",
        "        # Convert to DataFrame if it's a Dataset\n",
        "        test_df = test_dataset.to_pandas()\n",
        "    else:\n",
        "        test_df = test_dataset\n",
        "\n",
        "    # Process each example\n",
        "    for i, example in enumerate(test_df.itertuples()):\n",
        "        try:\n",
        "            # Check if dialogue attribute exists, otherwise try different attribute names\n",
        "            if hasattr(example, 'dialogue'):\n",
        "                dialogue = example.dialogue\n",
        "            elif hasattr(example, 'input_text'):\n",
        "                dialogue = example.input_text\n",
        "            else:\n",
        "                # Try to access by index for tuples\n",
        "                dialogue = example[test_df.columns.get_loc('dialogue') + 1]\n",
        "\n",
        "            print(f\"Processing example {i+1}/{len(test_df)}, dialogue length: {len(dialogue)}\")\n",
        "\n",
        "            input_text = f\"Summarize the following doctor-patient dialogue into a clinical note focusing on chief complaint, history of present illness, past medical history, diagnosis, and treatment plan: {dialogue}\"\n",
        "\n",
        "            inputs = tokenizer(\n",
        "                input_text,\n",
        "                max_length=512,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "            # Handle device placement\n",
        "            if torch.cuda.is_available():\n",
        "                inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
        "                model = model.to('cuda')\n",
        "\n",
        "            # Generate text with error handling\n",
        "            try:\n",
        "                outputs = model.generate(\n",
        "                    input_ids=inputs['input_ids'],\n",
        "                    attention_mask=inputs['attention_mask'],\n",
        "                    max_length=128,\n",
        "                    do_sample=True,\n",
        "                    top_p=0.95,\n",
        "                    top_k=50\n",
        "                )\n",
        "\n",
        "                generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "                print(f\"Generated text length: {len(generated_text)}\")\n",
        "                all_generated.append(generated_text)\n",
        "\n",
        "                # Check for presence of each target section\n",
        "                for section in target_sections:\n",
        "                    pattern = f\"<{section}>.*?</{section}>\"\n",
        "                    if re.search(pattern, generated_text, re.DOTALL):\n",
        "                        results[section][\"present\"] += 1\n",
        "                    results[section][\"total\"] += 1\n",
        "\n",
        "                # For ROUGE score, we need references\n",
        "                # Use section_text if available\n",
        "                if hasattr(example, 'section_text'):\n",
        "                    all_references.append(example.section_text)\n",
        "                else:\n",
        "                    # If no gold reference is available, add an empty string\n",
        "                    # This will affect ROUGE scores but prevent crashes\n",
        "                    all_references.append(\"\")\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Error during generation for example {i}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing example {i}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Calculate percentages\n",
        "    if len(results) > 0 and all(data[\"total\"] > 0 for data in results.values()):\n",
        "        section_coverage = {section: (data[\"present\"] / data[\"total\"]) * 100\n",
        "                           for section, data in results.items()}\n",
        "    else:\n",
        "        section_coverage = {section: 0 for section in target_sections}\n",
        "\n",
        "    # Calculate ROUGE scores only if we have both predictions and references\n",
        "    rouge_scores = {}\n",
        "    if len(all_generated) > 0 and len(all_references) > 0 and len(all_generated) == len(all_references):\n",
        "        try:\n",
        "            import evaluate\n",
        "            rouge = evaluate.load(\"rouge\")\n",
        "            rouge_scores = rouge.compute(\n",
        "                predictions=all_generated,\n",
        "                references=all_references,\n",
        "                use_stemmer=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error computing ROUGE scores: {str(e)}\")\n",
        "\n",
        "    print(\"Evaluation complete!\")\n",
        "    print(f\"Section coverage: {section_coverage}\")\n",
        "\n",
        "    return {\n",
        "        \"section_coverage\": section_coverage,\n",
        "        \"rouge_scores\": rouge_scores,\n",
        "        \"examples\": list(zip(all_generated[:5], all_references[:5]))  # Return a few examples\n",
        "    }\n",
        "\n",
        "# Updated function to handle edge cases\n",
        "def extract_sections(generated_text, target_sections):\n",
        "    \"\"\"\n",
        "    Extracts the specific sections from generated text\n",
        "    \"\"\"\n",
        "    extracted = {}\n",
        "    for section in target_sections:\n",
        "        pattern = f\"<{section}>(.*?)</{section}>\"\n",
        "        match = re.search(pattern, generated_text, re.DOTALL)\n",
        "        if match:\n",
        "            extracted[section] = match.group(1).strip()\n",
        "        else:\n",
        "            # Try a more flexible pattern in case the model didn't use exact XML tags\n",
        "            flexible_pattern = f\"{section}[:\\s]+(.*?)(?=\\s*(?:{section}|$))\"\n",
        "            flexible_match = re.search(flexible_pattern, generated_text, re.IGNORECASE | re.DOTALL)\n",
        "            if flexible_match:\n",
        "                extracted[section] = flexible_match.group(1).strip()\n",
        "            else:\n",
        "                extracted[section] = \"\"\n",
        "\n",
        "    return extracted\n",
        "\n",
        "# Function to test a single example\n",
        "def test_single_example(model, tokenizer, dialogue):\n",
        "    \"\"\"\n",
        "    Test the model on a single dialogue example and print detailed output\n",
        "    \"\"\"\n",
        "    target_sections = [\"chief_complaint\", \"history_of_present_illness\",\n",
        "                      \"past_medical_history\", \"diagnosis\", \"treatment_plan\"]\n",
        "\n",
        "    print(\"Input dialogue:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(dialogue[:500] + \"...\" if len(dialogue) > 500 else dialogue)\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    input_text = f\"Summarize the following doctor-patient dialogue into a clinical note focusing on chief complaint, history of present illness, past medical history, diagnosis, and treatment plan: {dialogue}\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Handle device placement\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
        "        model = model.to('cuda')\n",
        "\n",
        "    # Generate with basic parameters if generation_config is not defined\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        max_length=128,\n",
        "        do_sample=True,\n",
        "        top_p=0.95,\n",
        "        top_k=50\n",
        "    )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    print(\"\\nGenerated text:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(generated_text)\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Extract and display sections\n",
        "    sections = extract_sections(generated_text, target_sections)\n",
        "\n",
        "    print(\"\\nExtracted sections:\")\n",
        "    for section, content in sections.items():\n",
        "        print(f\"\\n### {section.upper().replace('_', ' ')} ###\")\n",
        "        print(content if content else \"[Not found]\")\n",
        "\n",
        "    return generated_text, sections\n",
        "\n",
        "# Function to process the test dataset with proper error handling\n",
        "def process_test_dataset(model, tokenizer, test_dataset, num_examples=5):\n",
        "    \"\"\"\n",
        "    Process a few examples from the test dataset to check functionality\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Convert to dataframe if needed\n",
        "    if hasattr(test_dataset, 'to_pandas'):\n",
        "        test_df = test_dataset.to_pandas()\n",
        "    else:\n",
        "        test_df = test_dataset\n",
        "\n",
        "    print(f\"Test dataset columns: {test_df.columns.tolist()}\")\n",
        "\n",
        "    # Process a limited number of examples\n",
        "    for i, row in enumerate(test_df.itertuples()):\n",
        "        if i >= num_examples:\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            # Try to get dialogue field\n",
        "            if hasattr(row, 'dialogue'):\n",
        "                dialogue = row.dialogue\n",
        "            elif hasattr(row, 'input_text'):\n",
        "                dialogue = row.input_text\n",
        "            else:\n",
        "                # Try to access by column index as fallback\n",
        "                dialogue = row[test_df.columns.get_loc('dialogue') + 1]\n",
        "\n",
        "            print(f\"\\nProcessing example {i+1}:\")\n",
        "            generated_text, sections = test_single_example(model, tokenizer, dialogue)\n",
        "            results.append({\n",
        "                \"dialogue\": dialogue,\n",
        "                \"generated_text\": generated_text,\n",
        "                \"sections\": sections\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing example {i}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9wTTh9S_iUq",
        "outputId": "ffeae351-1c1c-4249-8d1e-c3f3eec5150f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ID', 'section_header', 'section_text', 'dialogue']\n",
            "Index(['ID', 'section_header', 'section_text', 'dialogue'], dtype='object')\n",
            "Input dialogue:\n",
            "----------------------------------------\n",
            "Doctor: Good afternoon, sir. Did you just have a birthday? I don't have my chart with me right now, the nurse is bringing it. \n",
            "Patient: Good afternoon, sir. Yes, I just turned fifty five. \n",
            "Doctor: You identify as African American, correct? \n",
            "Patient: Yes, that's right. \n",
            "Doctor: When was your last visit, sir? \n",
            "Patient: Um, it was on July twenty ninth two thousand eight. \n",
            "Doctor: Yes, I see. Did we go over your M R I results? \n",
            "Patient: No, I was having those new seizures, remember?\n",
            "Doctor: Yes, I d...\n",
            "----------------------------------------\n",
            "\n",
            "Generated text:\n",
            "----------------------------------------\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Extracted sections:\n",
            "\n",
            "### CHIEF COMPLAINT ###\n",
            "[Not found]\n",
            "\n",
            "### HISTORY OF PRESENT ILLNESS ###\n",
            "[Not found]\n",
            "\n",
            "### PAST MEDICAL HISTORY ###\n",
            "[Not found]\n",
            "\n",
            "### DIAGNOSIS ###\n",
            "[Not found]\n",
            "\n",
            "### TREATMENT PLAN ###\n",
            "[Not found]\n",
            "Test dataset columns: ['ID', 'section_header', 'section_text', 'dialogue']\n",
            "\n",
            "Processing example 1:\n",
            "Input dialogue:\n",
            "----------------------------------------\n",
            "Doctor: Good afternoon, sir. Did you just have a birthday? I don't have my chart with me right now, the nurse is bringing it. \n",
            "Patient: Good afternoon, sir. Yes, I just turned fifty five. \n",
            "Doctor: You identify as African American, correct? \n",
            "Patient: Yes, that's right. \n",
            "Doctor: When was your last visit, sir? \n",
            "Patient: Um, it was on July twenty ninth two thousand eight. \n",
            "Doctor: Yes, I see. Did we go over your M R I results? \n",
            "Patient: No, I was having those new seizures, remember?\n",
            "Doctor: Yes, I d...\n",
            "----------------------------------------\n",
            "\n",
            "Generated text:\n",
            "----------------------------------------\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Extracted sections:\n",
            "\n",
            "### CHIEF COMPLAINT ###\n",
            "[Not found]\n",
            "\n",
            "### HISTORY OF PRESENT ILLNESS ###\n",
            "[Not found]\n",
            "\n",
            "### PAST MEDICAL HISTORY ###\n",
            "[Not found]\n",
            "\n",
            "### DIAGNOSIS ###\n",
            "[Not found]\n",
            "\n",
            "### TREATMENT PLAN ###\n",
            "[Not found]\n",
            "\n",
            "Processing example 2:\n",
            "Input dialogue:\n",
            "----------------------------------------\n",
            "Doctor: Any medical issues running in your families? \n",
            "Patient: Oh yes, stroke. \n",
            "Doctor: Anything else? \n",
            "Patient: Sleep apnea.\n",
            "----------------------------------------\n",
            "\n",
            "Generated text:\n",
            "----------------------------------------\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Extracted sections:\n",
            "\n",
            "### CHIEF COMPLAINT ###\n",
            "[Not found]\n",
            "\n",
            "### HISTORY OF PRESENT ILLNESS ###\n",
            "[Not found]\n",
            "\n",
            "### PAST MEDICAL HISTORY ###\n",
            "[Not found]\n",
            "\n",
            "### DIAGNOSIS ###\n",
            "[Not found]\n",
            "\n",
            "### TREATMENT PLAN ###\n",
            "[Not found]\n",
            "\n",
            "Processing example 3:\n",
            "Input dialogue:\n",
            "----------------------------------------\n",
            "Doctor: Any pain in your muscles? \n",
            "Patient: No, no pain.\n",
            "Doctor: How about joint pain? \n",
            "Patient: Um no, I don't feel any joint pain.\n",
            "Doctor: Okay, good.\n",
            "Doctor: Do you feel any stiffness or weakness in your muscle? \n",
            "Patient: Um, nothing like that.\n",
            "Doctor: Do you have any back pain? \n",
            "Patient: No.\n",
            "Doctor: Okay.\n",
            "----------------------------------------\n",
            "\n",
            "Generated text:\n",
            "----------------------------------------\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Extracted sections:\n",
            "\n",
            "### CHIEF COMPLAINT ###\n",
            "[Not found]\n",
            "\n",
            "### HISTORY OF PRESENT ILLNESS ###\n",
            "[Not found]\n",
            "\n",
            "### PAST MEDICAL HISTORY ###\n",
            "[Not found]\n",
            "\n",
            "### DIAGNOSIS ###\n",
            "[Not found]\n",
            "\n",
            "### TREATMENT PLAN ###\n",
            "[Not found]\n",
            "Starting evaluation on 200 test examples...\n",
            "Processing example 1/200, dialogue length: 747\n",
            "Generated text length: 0\n",
            "Processing example 2/200, dialogue length: 125\n",
            "Generated text length: 0\n",
            "Processing example 3/200, dialogue length: 310\n",
            "Generated text length: 0\n",
            "Processing example 4/200, dialogue length: 144\n",
            "Generated text length: 0\n",
            "Processing example 5/200, dialogue length: 302\n",
            "Generated text length: 0\n",
            "Processing example 6/200, dialogue length: 239\n",
            "Generated text length: 0\n",
            "Processing example 7/200, dialogue length: 438\n",
            "Generated text length: 0\n",
            "Processing example 8/200, dialogue length: 747\n",
            "Generated text length: 0\n",
            "Processing example 9/200, dialogue length: 426\n",
            "Generated text length: 0\n",
            "Processing example 10/200, dialogue length: 74\n",
            "Generated text length: 0\n",
            "Processing example 11/200, dialogue length: 634\n",
            "Generated text length: 0\n",
            "Processing example 12/200, dialogue length: 602\n",
            "Generated text length: 0\n",
            "Processing example 13/200, dialogue length: 472\n",
            "Generated text length: 0\n",
            "Processing example 14/200, dialogue length: 342\n",
            "Generated text length: 0\n",
            "Processing example 15/200, dialogue length: 494\n",
            "Generated text length: 0\n",
            "Processing example 16/200, dialogue length: 314\n",
            "Generated text length: 0\n",
            "Processing example 17/200, dialogue length: 266\n",
            "Generated text length: 0\n",
            "Processing example 18/200, dialogue length: 239\n",
            "Generated text length: 0\n",
            "Processing example 19/200, dialogue length: 302\n",
            "Generated text length: 0\n",
            "Processing example 20/200, dialogue length: 1828\n",
            "Generated text length: 492\n",
            "Processing example 21/200, dialogue length: 1018\n",
            "Generated text length: 0\n",
            "Processing example 22/200, dialogue length: 680\n",
            "Generated text length: 573\n",
            "Processing example 23/200, dialogue length: 647\n",
            "Generated text length: 0\n",
            "Processing example 24/200, dialogue length: 591\n",
            "Generated text length: 0\n",
            "Processing example 25/200, dialogue length: 327\n",
            "Generated text length: 0\n",
            "Processing example 26/200, dialogue length: 505\n",
            "Generated text length: 0\n",
            "Processing example 27/200, dialogue length: 655\n",
            "Generated text length: 0\n",
            "Processing example 28/200, dialogue length: 95\n",
            "Generated text length: 0\n",
            "Processing example 29/200, dialogue length: 166\n",
            "Generated text length: 0\n",
            "Processing example 30/200, dialogue length: 145\n",
            "Generated text length: 0\n",
            "Processing example 31/200, dialogue length: 304\n",
            "Generated text length: 0\n",
            "Processing example 32/200, dialogue length: 3320\n",
            "Generated text length: 560\n",
            "Processing example 33/200, dialogue length: 365\n",
            "Generated text length: 0\n",
            "Processing example 34/200, dialogue length: 214\n",
            "Generated text length: 0\n",
            "Processing example 35/200, dialogue length: 204\n",
            "Generated text length: 0\n",
            "Processing example 36/200, dialogue length: 369\n",
            "Generated text length: 0\n",
            "Processing example 37/200, dialogue length: 649\n",
            "Generated text length: 0\n",
            "Processing example 38/200, dialogue length: 361\n",
            "Generated text length: 0\n",
            "Processing example 39/200, dialogue length: 1562\n",
            "Generated text length: 556\n",
            "Processing example 40/200, dialogue length: 436\n",
            "Generated text length: 0\n",
            "Processing example 41/200, dialogue length: 386\n",
            "Generated text length: 0\n",
            "Processing example 42/200, dialogue length: 252\n",
            "Generated text length: 0\n",
            "Processing example 43/200, dialogue length: 535\n",
            "Generated text length: 0\n",
            "Processing example 44/200, dialogue length: 132\n",
            "Generated text length: 0\n",
            "Processing example 45/200, dialogue length: 403\n",
            "Generated text length: 0\n",
            "Processing example 46/200, dialogue length: 158\n",
            "Generated text length: 0\n",
            "Processing example 47/200, dialogue length: 682\n",
            "Generated text length: 496\n",
            "Processing example 48/200, dialogue length: 844\n",
            "Generated text length: 0\n",
            "Processing example 49/200, dialogue length: 350\n",
            "Generated text length: 0\n",
            "Processing example 50/200, dialogue length: 2844\n",
            "Generated text length: 465\n",
            "Processing example 51/200, dialogue length: 1290\n",
            "Generated text length: 508\n",
            "Processing example 52/200, dialogue length: 81\n",
            "Generated text length: 0\n",
            "Processing example 53/200, dialogue length: 111\n",
            "Generated text length: 0\n",
            "Processing example 54/200, dialogue length: 478\n",
            "Generated text length: 0\n",
            "Processing example 55/200, dialogue length: 1142\n",
            "Generated text length: 0\n",
            "Processing example 56/200, dialogue length: 372\n",
            "Generated text length: 294\n",
            "Processing example 57/200, dialogue length: 203\n",
            "Generated text length: 0\n",
            "Processing example 58/200, dialogue length: 609\n",
            "Generated text length: 0\n",
            "Processing example 59/200, dialogue length: 831\n",
            "Generated text length: 0\n",
            "Processing example 60/200, dialogue length: 287\n",
            "Generated text length: 0\n",
            "Processing example 61/200, dialogue length: 381\n",
            "Generated text length: 0\n",
            "Processing example 62/200, dialogue length: 112\n",
            "Generated text length: 0\n",
            "Processing example 63/200, dialogue length: 275\n",
            "Generated text length: 0\n",
            "Processing example 64/200, dialogue length: 2216\n",
            "Generated text length: 563\n",
            "Processing example 65/200, dialogue length: 949\n",
            "Generated text length: 511\n",
            "Processing example 66/200, dialogue length: 209\n",
            "Generated text length: 0\n",
            "Processing example 67/200, dialogue length: 1838\n",
            "Generated text length: 0\n",
            "Processing example 68/200, dialogue length: 1747\n",
            "Generated text length: 560\n",
            "Processing example 69/200, dialogue length: 195\n",
            "Generated text length: 0\n",
            "Processing example 70/200, dialogue length: 236\n",
            "Generated text length: 0\n",
            "Processing example 71/200, dialogue length: 240\n",
            "Generated text length: 0\n",
            "Processing example 72/200, dialogue length: 208\n",
            "Generated text length: 0\n",
            "Processing example 73/200, dialogue length: 105\n",
            "Generated text length: 0\n",
            "Processing example 74/200, dialogue length: 877\n",
            "Generated text length: 0\n",
            "Processing example 75/200, dialogue length: 842\n",
            "Generated text length: 0\n",
            "Processing example 76/200, dialogue length: 1155\n",
            "Generated text length: 0\n",
            "Processing example 77/200, dialogue length: 89\n",
            "Generated text length: 0\n",
            "Processing example 78/200, dialogue length: 249\n",
            "Generated text length: 0\n",
            "Processing example 79/200, dialogue length: 847\n",
            "Generated text length: 0\n",
            "Processing example 80/200, dialogue length: 270\n",
            "Generated text length: 0\n",
            "Processing example 81/200, dialogue length: 110\n",
            "Generated text length: 0\n",
            "Processing example 82/200, dialogue length: 554\n",
            "Generated text length: 0\n",
            "Processing example 83/200, dialogue length: 175\n",
            "Generated text length: 0\n",
            "Processing example 84/200, dialogue length: 226\n",
            "Generated text length: 0\n",
            "Processing example 85/200, dialogue length: 277\n",
            "Generated text length: 0\n",
            "Processing example 86/200, dialogue length: 73\n",
            "Generated text length: 0\n",
            "Processing example 87/200, dialogue length: 256\n",
            "Generated text length: 0\n",
            "Processing example 88/200, dialogue length: 553\n",
            "Generated text length: 0\n",
            "Processing example 89/200, dialogue length: 596\n",
            "Generated text length: 0\n",
            "Processing example 90/200, dialogue length: 937\n",
            "Generated text length: 0\n",
            "Processing example 91/200, dialogue length: 640\n",
            "Generated text length: 0\n",
            "Processing example 92/200, dialogue length: 634\n",
            "Generated text length: 0\n",
            "Processing example 93/200, dialogue length: 455\n",
            "Generated text length: 0\n",
            "Processing example 94/200, dialogue length: 266\n",
            "Generated text length: 0\n",
            "Processing example 95/200, dialogue length: 292\n",
            "Generated text length: 0\n",
            "Processing example 96/200, dialogue length: 2281\n",
            "Generated text length: 583\n",
            "Processing example 97/200, dialogue length: 81\n",
            "Generated text length: 0\n",
            "Processing example 98/200, dialogue length: 296\n",
            "Generated text length: 0\n",
            "Processing example 99/200, dialogue length: 441\n",
            "Generated text length: 0\n",
            "Processing example 100/200, dialogue length: 58\n",
            "Generated text length: 0\n",
            "Processing example 101/200, dialogue length: 1372\n",
            "Generated text length: 0\n",
            "Processing example 102/200, dialogue length: 80\n",
            "Generated text length: 0\n",
            "Processing example 103/200, dialogue length: 128\n",
            "Generated text length: 0\n",
            "Processing example 104/200, dialogue length: 1851\n",
            "Generated text length: 561\n",
            "Processing example 105/200, dialogue length: 282\n",
            "Generated text length: 0\n",
            "Processing example 106/200, dialogue length: 413\n",
            "Generated text length: 0\n",
            "Processing example 107/200, dialogue length: 59\n",
            "Generated text length: 0\n",
            "Processing example 108/200, dialogue length: 623\n",
            "Generated text length: 0\n",
            "Processing example 109/200, dialogue length: 582\n",
            "Generated text length: 0\n",
            "Processing example 110/200, dialogue length: 92\n",
            "Generated text length: 0\n",
            "Processing example 111/200, dialogue length: 1755\n",
            "Generated text length: 533\n",
            "Processing example 112/200, dialogue length: 275\n",
            "Generated text length: 0\n",
            "Processing example 113/200, dialogue length: 273\n",
            "Generated text length: 0\n",
            "Processing example 114/200, dialogue length: 183\n",
            "Generated text length: 0\n",
            "Processing example 115/200, dialogue length: 149\n",
            "Generated text length: 0\n",
            "Processing example 116/200, dialogue length: 337\n",
            "Generated text length: 385\n",
            "Processing example 117/200, dialogue length: 446\n",
            "Generated text length: 0\n",
            "Processing example 118/200, dialogue length: 91\n",
            "Generated text length: 0\n",
            "Processing example 119/200, dialogue length: 149\n",
            "Generated text length: 0\n",
            "Processing example 120/200, dialogue length: 447\n",
            "Generated text length: 0\n",
            "Processing example 121/200, dialogue length: 1590\n",
            "Generated text length: 28\n",
            "Processing example 122/200, dialogue length: 97\n",
            "Generated text length: 0\n",
            "Processing example 123/200, dialogue length: 633\n",
            "Generated text length: 0\n",
            "Processing example 124/200, dialogue length: 203\n",
            "Generated text length: 0\n",
            "Processing example 125/200, dialogue length: 267\n",
            "Generated text length: 0\n",
            "Processing example 126/200, dialogue length: 1840\n",
            "Generated text length: 0\n",
            "Processing example 127/200, dialogue length: 1292\n",
            "Generated text length: 559\n",
            "Processing example 128/200, dialogue length: 179\n",
            "Generated text length: 0\n",
            "Processing example 129/200, dialogue length: 1556\n",
            "Generated text length: 0\n",
            "Processing example 130/200, dialogue length: 628\n",
            "Generated text length: 0\n",
            "Processing example 131/200, dialogue length: 118\n",
            "Generated text length: 0\n",
            "Processing example 132/200, dialogue length: 192\n",
            "Generated text length: 0\n",
            "Processing example 133/200, dialogue length: 157\n",
            "Generated text length: 0\n",
            "Processing example 134/200, dialogue length: 251\n",
            "Generated text length: 0\n",
            "Processing example 135/200, dialogue length: 338\n",
            "Generated text length: 0\n",
            "Processing example 136/200, dialogue length: 579\n",
            "Generated text length: 0\n",
            "Processing example 137/200, dialogue length: 1586\n",
            "Generated text length: 540\n",
            "Processing example 138/200, dialogue length: 525\n",
            "Generated text length: 0\n",
            "Processing example 139/200, dialogue length: 223\n",
            "Generated text length: 0\n",
            "Processing example 140/200, dialogue length: 1572\n",
            "Generated text length: 486\n",
            "Processing example 141/200, dialogue length: 67\n",
            "Generated text length: 0\n",
            "Processing example 142/200, dialogue length: 1201\n",
            "Generated text length: 0\n",
            "Processing example 143/200, dialogue length: 117\n",
            "Generated text length: 0\n",
            "Processing example 144/200, dialogue length: 212\n",
            "Generated text length: 0\n",
            "Processing example 145/200, dialogue length: 251\n",
            "Generated text length: 0\n",
            "Processing example 146/200, dialogue length: 565\n",
            "Generated text length: 0\n",
            "Processing example 147/200, dialogue length: 1377\n",
            "Generated text length: 0\n",
            "Processing example 148/200, dialogue length: 373\n",
            "Generated text length: 0\n",
            "Processing example 149/200, dialogue length: 446\n",
            "Generated text length: 0\n",
            "Processing example 150/200, dialogue length: 519\n",
            "Generated text length: 0\n",
            "Processing example 151/200, dialogue length: 1245\n",
            "Generated text length: 485\n",
            "Processing example 152/200, dialogue length: 216\n",
            "Generated text length: 0\n",
            "Processing example 153/200, dialogue length: 1029\n",
            "Generated text length: 538\n",
            "Processing example 154/200, dialogue length: 119\n",
            "Generated text length: 0\n",
            "Processing example 155/200, dialogue length: 514\n",
            "Generated text length: 0\n",
            "Processing example 156/200, dialogue length: 600\n",
            "Generated text length: 0\n",
            "Processing example 157/200, dialogue length: 215\n",
            "Generated text length: 0\n",
            "Processing example 158/200, dialogue length: 418\n",
            "Generated text length: 0\n",
            "Processing example 159/200, dialogue length: 313\n",
            "Generated text length: 0\n",
            "Processing example 160/200, dialogue length: 656\n",
            "Generated text length: 549\n",
            "Processing example 161/200, dialogue length: 151\n",
            "Generated text length: 0\n",
            "Processing example 162/200, dialogue length: 158\n",
            "Generated text length: 0\n",
            "Processing example 163/200, dialogue length: 645\n",
            "Generated text length: 0\n",
            "Processing example 164/200, dialogue length: 914\n",
            "Generated text length: 559\n",
            "Processing example 165/200, dialogue length: 460\n",
            "Generated text length: 417\n",
            "Processing example 166/200, dialogue length: 289\n",
            "Generated text length: 0\n",
            "Processing example 167/200, dialogue length: 870\n",
            "Generated text length: 615\n",
            "Processing example 168/200, dialogue length: 231\n",
            "Generated text length: 0\n",
            "Processing example 169/200, dialogue length: 1357\n",
            "Generated text length: 0\n",
            "Processing example 170/200, dialogue length: 371\n",
            "Generated text length: 0\n",
            "Processing example 171/200, dialogue length: 1811\n",
            "Generated text length: 591\n",
            "Processing example 172/200, dialogue length: 1099\n",
            "Generated text length: 0\n",
            "Processing example 173/200, dialogue length: 257\n",
            "Generated text length: 0\n",
            "Processing example 174/200, dialogue length: 337\n",
            "Generated text length: 0\n",
            "Processing example 175/200, dialogue length: 545\n",
            "Generated text length: 0\n",
            "Processing example 176/200, dialogue length: 166\n",
            "Generated text length: 0\n",
            "Processing example 177/200, dialogue length: 185\n",
            "Generated text length: 0\n",
            "Processing example 178/200, dialogue length: 1442\n",
            "Generated text length: 0\n",
            "Processing example 179/200, dialogue length: 80\n",
            "Generated text length: 0\n",
            "Processing example 180/200, dialogue length: 1874\n",
            "Generated text length: 495\n",
            "Processing example 181/200, dialogue length: 250\n",
            "Generated text length: 0\n",
            "Processing example 182/200, dialogue length: 619\n",
            "Generated text length: 0\n",
            "Processing example 183/200, dialogue length: 219\n",
            "Generated text length: 0\n",
            "Processing example 184/200, dialogue length: 158\n",
            "Generated text length: 0\n",
            "Processing example 185/200, dialogue length: 252\n",
            "Generated text length: 0\n",
            "Processing example 186/200, dialogue length: 663\n",
            "Generated text length: 0\n",
            "Processing example 187/200, dialogue length: 657\n",
            "Generated text length: 0\n",
            "Processing example 188/200, dialogue length: 441\n",
            "Generated text length: 0\n",
            "Processing example 189/200, dialogue length: 1250\n",
            "Generated text length: 532\n",
            "Processing example 190/200, dialogue length: 324\n",
            "Generated text length: 0\n",
            "Processing example 191/200, dialogue length: 868\n",
            "Generated text length: 0\n",
            "Processing example 192/200, dialogue length: 526\n",
            "Generated text length: 0\n",
            "Processing example 193/200, dialogue length: 732\n",
            "Generated text length: 0\n",
            "Processing example 194/200, dialogue length: 380\n",
            "Generated text length: 0\n",
            "Processing example 195/200, dialogue length: 155\n",
            "Generated text length: 0\n",
            "Processing example 196/200, dialogue length: 1057\n",
            "Generated text length: 0\n",
            "Processing example 197/200, dialogue length: 208\n",
            "Generated text length: 0\n",
            "Processing example 198/200, dialogue length: 602\n",
            "Generated text length: 0\n",
            "Processing example 199/200, dialogue length: 227\n",
            "Generated text length: 0\n",
            "Processing example 200/200, dialogue length: 145\n",
            "Generated text length: 0\n",
            "Evaluation complete!\n",
            "Section coverage: {'chief_complaint': 0.0, 'history_of_present_illness': 0.0, 'past_medical_history': 0.0, 'diagnosis': 0.0, 'treatment_plan': 0.0}\n"
          ]
        }
      ],
      "source": [
        "# 1. First, check if your dataset has the right structure:\n",
        "print(test_dataset.column_names)  # For datasets.Dataset objects\n",
        "# OR\n",
        "print(test_data.columns)  # For pandas DataFrames\n",
        "\n",
        "# 2. Test with a single example first:\n",
        "if len(test_dataset) > 0:\n",
        "    example = test_dataset[0]\n",
        "    dialogue = example['dialogue']  # adjust field name if needed\n",
        "    test_single_example(model, tokenizer, dialogue)\n",
        "\n",
        "# 3. Process a few test examples:\n",
        "results = process_test_dataset(model, tokenizer, test_dataset, num_examples=3)\n",
        "\n",
        "# 4. Run full evaluation only after verifying the above steps work:\n",
        "target_sections = [\"chief_complaint\", \"history_of_present_illness\",\n",
        "                   \"past_medical_history\", \"diagnosis\", \"treatment_plan\"]\n",
        "eval_results = evaluate_generated_notes(model, tokenizer, test_dataset, target_sections)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0be5616526254073be89c9daa883709f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d2d0292feef4eafad5fb0a44d22446c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d4257e3cb3549e6aaffe0d805a65cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_535da7223a8349f79f5b4251095dc6f2",
              "IPY_MODEL_96a5050fac544206866387f5485679b1",
              "IPY_MODEL_fda5ff95555e455faf99add089863ef9"
            ],
            "layout": "IPY_MODEL_4057bdfdd9f34eccbf47c63618942c81"
          }
        },
        "12c8ce11427d4fb0beef8883bc3f7a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19e25217828f498389bf2e9f68b04574": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e6d56fe5b40408fb62afaacfe28cfc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "223fcf240b06456dada4d28557e59e93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "267d423015c44edd96c87ca885a8716a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeb377e1762d47099c8385e17ee1df17",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0be5616526254073be89c9daa883709f",
            "value": 1355863
          }
        },
        "3015634104024df786ec272cd03e56ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3445c8ee4ac2462293a85012854adb27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e952e84c93411992b6a377a1e56da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b6f3d368fde4a77979ec0bfd69cb885": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_500a55755b37402e9b894a9df3541609",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e7ecf62a542444dbad0653b8d0f7ccf",
            "value": 6270
          }
        },
        "4057bdfdd9f34eccbf47c63618942c81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c6f6d4766c4d579d8d631d6676a464": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b43416263fe49a8a5c3442cf88a361d",
            "placeholder": "​",
            "style": "IPY_MODEL_7fa1f0a1618f4b88b650047a93303426",
            "value": "merges.txt: 100%"
          }
        },
        "4b276cf9ceff41fa9f9c3b4416f41d27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b43416263fe49a8a5c3442cf88a361d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e7ecf62a542444dbad0653b8d0f7ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "500a55755b37402e9b894a9df3541609": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c55af2db7c4bcbb054b46f22519607": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f186e2e8c1434eb861d8be77dceb3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5217ecaa653647a68659fd986d01051e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "535da7223a8349f79f5b4251095dc6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e6d56fe5b40408fb62afaacfe28cfc4",
            "placeholder": "​",
            "style": "IPY_MODEL_0d2d0292feef4eafad5fb0a44d22446c",
            "value": "vocab.json: 100%"
          }
        },
        "5731898279ea4334b7ce5808d315398f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_223fcf240b06456dada4d28557e59e93",
            "placeholder": "​",
            "style": "IPY_MODEL_34e952e84c93411992b6a377a1e56da5",
            "value": "tokenizer.json: 100%"
          }
        },
        "577f0d40cab84fb6a0105b3e55569032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19e25217828f498389bf2e9f68b04574",
            "placeholder": "​",
            "style": "IPY_MODEL_973b065780a64812a8698e911e0bce79",
            "value": " 1.72k/1.72k [00:00&lt;00:00, 206kB/s]"
          }
        },
        "5780094675234af2aa3840ce9daf4bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c65fc6dd2734e6c83edbb4bfbaa1a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e43d73217494233bee0a0b5237dff62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75136276a6bb47a494a35e7153b176ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c790f143d54c54ada7efb8cdcc1ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42c6f6d4766c4d579d8d631d6676a464",
              "IPY_MODEL_e812eae1208b4b709e452cf76f9c775f",
              "IPY_MODEL_91cc733fc0e14a1a952d5dad673af1aa"
            ],
            "layout": "IPY_MODEL_5217ecaa653647a68659fd986d01051e"
          }
        },
        "7a8da94f35fb42208437ee163f11c84a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d62209128c84af187714e5865cec4b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f23f93af0db420c81f503750f3903ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa1f0a1618f4b88b650047a93303426": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84da64751bd741c48b36f941f30c8424": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c515cb6ceb34266acb186f90d70a069": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84da64751bd741c48b36f941f30c8424",
            "placeholder": "​",
            "style": "IPY_MODEL_bfb54d99f29b4dea94914bbb5acd060d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 4.56MB/s]"
          }
        },
        "91cc733fc0e14a1a952d5dad673af1aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f51dbf6fc0324b5688ca12e522eeea9f",
            "placeholder": "​",
            "style": "IPY_MODEL_f4b437aff4a2464fb276607bf1852b40",
            "value": " 456k/456k [00:00&lt;00:00, 13.8MB/s]"
          }
        },
        "9585f62b979240c59837fa9f7c4d7983": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a76aee8546484835aa76e560ac527d63",
              "IPY_MODEL_3b6f3d368fde4a77979ec0bfd69cb885",
              "IPY_MODEL_992b93761c314167a4ee697e5703362b"
            ],
            "layout": "IPY_MODEL_e70dc9db261d4fb3b3b352ed88d6efcd"
          }
        },
        "96a5050fac544206866387f5485679b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d62209128c84af187714e5865cec4b4",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c74cfe70d79d4d32944cfe6553f8c69e",
            "value": 898823
          }
        },
        "973b065780a64812a8698e911e0bce79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "981494c900b044ada7731782416521bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "992b93761c314167a4ee697e5703362b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a09c92f283454b2983fef91504f8d7c8",
            "placeholder": "​",
            "style": "IPY_MODEL_adeba752d52a4e0abab5839a23563581",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 531kB/s]"
          }
        },
        "a09c92f283454b2983fef91504f8d7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e0093d010d42dfa7b59a20b559b4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a76aee8546484835aa76e560ac527d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a8da94f35fb42208437ee163f11c84a",
            "placeholder": "​",
            "style": "IPY_MODEL_cf3e8fdc3de74db1b1cb231d510282b6",
            "value": "Downloading builder script: 100%"
          }
        },
        "adeba752d52a4e0abab5839a23563581": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeb377e1762d47099c8385e17ee1df17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b432056f1b0a4b52803f74d65d3bbf9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc83094bab0f4638812091b9c71f01fb",
              "IPY_MODEL_cfb6070847484775ac9d2a390b2c6375",
              "IPY_MODEL_e78d74e5531e435b9ae435d06f57ee88"
            ],
            "layout": "IPY_MODEL_3015634104024df786ec272cd03e56ba"
          }
        },
        "bfb54d99f29b4dea94914bbb5acd060d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c74cfe70d79d4d32944cfe6553f8c69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc83094bab0f4638812091b9c71f01fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c55af2db7c4bcbb054b46f22519607",
            "placeholder": "​",
            "style": "IPY_MODEL_ef2e148564dc419b95252746978bf99c",
            "value": "model.safetensors: 100%"
          }
        },
        "cd1c71bb0ac046df8581e169548fa17d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf3e8fdc3de74db1b1cb231d510282b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfb6070847484775ac9d2a390b2c6375": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51f186e2e8c1434eb861d8be77dceb3a",
            "max": 557709915,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3e0093d010d42dfa7b59a20b559b4e5",
            "value": 557709915
          }
        },
        "d96af0d326444c22a48ed534a7a510c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75136276a6bb47a494a35e7153b176ce",
            "placeholder": "​",
            "style": "IPY_MODEL_5780094675234af2aa3840ce9daf4bd9",
            "value": "config.json: 100%"
          }
        },
        "db0c1d4480f245d09338173db035b9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5731898279ea4334b7ce5808d315398f",
              "IPY_MODEL_267d423015c44edd96c87ca885a8716a",
              "IPY_MODEL_8c515cb6ceb34266acb186f90d70a069"
            ],
            "layout": "IPY_MODEL_dfe88ed6fd9142e993bd6dcdc740a3d8"
          }
        },
        "dfe88ed6fd9142e993bd6dcdc740a3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e16462581b12495e9f0f9861c8a8e1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5aa2e52fe4845a9b9b6a37262050b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd1c71bb0ac046df8581e169548fa17d",
            "max": 1716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e16462581b12495e9f0f9861c8a8e1c7",
            "value": 1716
          }
        },
        "e70dc9db261d4fb3b3b352ed88d6efcd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e78d74e5531e435b9ae435d06f57ee88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f23f93af0db420c81f503750f3903ca",
            "placeholder": "​",
            "style": "IPY_MODEL_5c65fc6dd2734e6c83edbb4bfbaa1a2c",
            "value": " 558M/558M [00:05&lt;00:00, 158MB/s]"
          }
        },
        "e812eae1208b4b709e452cf76f9c775f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3445c8ee4ac2462293a85012854adb27",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12c8ce11427d4fb0beef8883bc3f7a2a",
            "value": 456318
          }
        },
        "ef2e148564dc419b95252746978bf99c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4b437aff4a2464fb276607bf1852b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f51dbf6fc0324b5688ca12e522eeea9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda5ff95555e455faf99add089863ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b276cf9ceff41fa9f9c3b4416f41d27",
            "placeholder": "​",
            "style": "IPY_MODEL_981494c900b044ada7731782416521bf",
            "value": " 899k/899k [00:00&lt;00:00, 5.19MB/s]"
          }
        },
        "ff9ca662cb37480eba5013f189022130": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d96af0d326444c22a48ed534a7a510c7",
              "IPY_MODEL_e5aa2e52fe4845a9b9b6a37262050b72",
              "IPY_MODEL_577f0d40cab84fb6a0105b3e55569032"
            ],
            "layout": "IPY_MODEL_5e43d73217494233bee0a0b5237dff62"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
